{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyJLfLc6XD_t"
      },
      "outputs": [],
      "source": [
        "# ANN OCR trained with Noise\n",
        "# numpy/tensorflow/keras\n",
        "#\n",
        "# ICIN/IC Ex1 - APR/2023\n",
        "# created by Adolfo Bauchspiess and adapted by Gabriel Tambara Rabelo\n",
        "# workspace: Google Colab\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.lines as lines\n",
        "from keras.models import Sequential\n",
        "from keras.models import clone_model\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorflow as tf\n",
        "\n",
        "def geraChar():\n",
        "    P=np.zeros((63,16),dtype=int);\n",
        "    T=np.eye(16,dtype=int);\n",
        "    P[:,0]=[\t\t\t#A\n",
        "    1,1,1,0,0,0,0,\n",
        "    1,0,0,1,0,0,0,\n",
        "    1,0,0,0,1,0,0,\n",
        "    1,0,0,0,1,0,0,\n",
        "    1,1,1,1,1,1,0,\n",
        "    1,0,0,0,0,1,0,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1\n",
        "    ]\n",
        "    P[:,1]=[\t\t\t#B\n",
        "    1,1,1,1,0,0,0,\n",
        "    1,0,0,0,1,0,0,\n",
        "    1,0,0,0,0,1,0,\n",
        "    1,0,0,0,0,1,0,\n",
        "    1,0,0,1,1,1,0,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,1,1,1,1,1,0\n",
        "    ]\n",
        "    P[:,2]=[\t\t\t#E\n",
        "    1,1,1,1,1,1,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,1,1,1,1,1,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,1,1,1,1,1,1   \n",
        "    ]\n",
        "    P[:,3]=[\t\t\t#G\n",
        "    0,1,1,1,1,0,0,\n",
        "    1,1,0,0,0,1,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,1,1,1,0,\n",
        "    1,1,0,0,0,1,1,\n",
        "    1,1,0,0,0,0,1,\n",
        "    1,1,0,0,0,0,1,\n",
        "    1,1,1,1,1,1,1\n",
        "    ]\n",
        "    P[:,4]=[\t\t\t#I\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,0,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0\n",
        "    ]\n",
        "    P[:,5]=[\t\t\t#L\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,1,\n",
        "    1,1,1,1,1,1,1\n",
        "    ]\n",
        "    P[:,6]=[\t\t#M\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,1,0,0,0,1,1,\n",
        "    1,1,1,0,1,1,1,\n",
        "    1,1,1,0,1,1,1,\n",
        "    1,1,0,1,0,1,1,\n",
        "    1,1,0,0,0,1,1,\n",
        "    1,1,0,0,0,1,1,\n",
        "    1,1,0,0,0,1,1,\n",
        "    1,1,0,0,0,1,1\n",
        "    ]\n",
        "    P[:,7]=[\t\t#R\n",
        "    1,1,1,1,1,0,0,\n",
        "    1,1,0,0,0,1,0,\n",
        "    1,1,0,0,0,1,0,\n",
        "    1,1,0,0,1,0,0,\n",
        "    1,1,1,1,1,0,0,\n",
        "    1,1,0,0,0,1,0,\n",
        "    1,1,0,0,0,1,0,\n",
        "    1,1,0,0,0,0,1,\n",
        "    1,1,0,0,0,0,1\n",
        "    ]\n",
        "    P[:,8]=[\t\t\t#T\n",
        "    0,0,0,1,0,0,0,\n",
        "    1,1,1,1,1,1,1,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0,\n",
        "    0,0,0,1,0,0,0\n",
        "    ]\n",
        "    P[:,9]=[\t\t\t#O\n",
        "    0,1,1,1,1,1,0,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,0,0,0,0,0,1,\n",
        "    1,1,1,1,1,1,1\n",
        "    ]\n",
        "    P[:,10]=[\t\t\t#1\n",
        "    0,0,0,1,1,0,0,\n",
        "    0,0,1,1,1,0,0,\n",
        "    0,1,1,1,1,0,0,\n",
        "    0,0,0,1,1,0,0,\n",
        "    0,0,0,1,1,0,0,\n",
        "    0,0,0,1,1,0,0,\n",
        "    0,0,0,1,1,0,0,\n",
        "    0,0,0,1,1,0,0,\n",
        "    0,0,0,1,1,0,0\n",
        "    ]\n",
        "    P[:,11]=[\t\t\t#2\n",
        "    0,0,1,1,1,1,0,\n",
        "    0,1,0,0,0,1,1,\n",
        "    0,1,1,0,0,1,1,\n",
        "    0,0,0,0,1,1,1,\n",
        "    0,0,0,1,1,1,1,\n",
        "    0,0,1,1,1,0,0,\n",
        "    0,1,1,1,0,0,0,\n",
        "    0,1,1,0,0,0,0,\n",
        "    0,1,1,1,1,1,1\n",
        "    ]\n",
        "    P[:,12]=[\t\t\t#3    \n",
        "    0,0,1,1,1,1,0,\n",
        "    0,1,0,0,0,1,1,\n",
        "    0,1,1,0,0,1,1,\n",
        "    0,0,0,0,0,1,1,\n",
        "    0,0,1,1,1,1,0,\n",
        "    0,0,0,0,0,1,1,\n",
        "    0,0,0,0,0,1,1,\n",
        "    0,1,0,0,0,1,1,\n",
        "    0,0,1,1,1,1,0\n",
        "    ]\n",
        "    P[:,13]=[\t\t\t#4\n",
        "    0,0,0,0,1,1,0,\n",
        "    0,0,0,1,1,1,0,\n",
        "    0,0,1,1,1,1,0,\n",
        "    0,1,1,0,1,1,0,\n",
        "    1,1,0,0,1,1,0,\n",
        "    1,1,0,0,1,1,0,\n",
        "    1,1,1,1,1,1,1,\n",
        "    0,0,0,0,1,1,0,\n",
        "    0,0,0,0,1,1,0\n",
        "    ]\n",
        "    P[:,14]=[\t\t\t#5\n",
        "    1,1,1,1,1,1,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,0,0,0,0,0,0,\n",
        "    1,1,1,1,1,0,0,\n",
        "    0,0,0,0,1,1,1,\n",
        "    0,0,0,0,0,1,1,\n",
        "    0,0,0,0,0,1,1,\n",
        "    1,0,0,0,1,1,1,\n",
        "    1,1,1,1,1,1,0   \n",
        "    ]\n",
        "    P[:,15]=[\t\t\t#6\n",
        "    0,1,1,1,1,1,0,\n",
        "    1,1,1,0,0,1,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,0,0,0,0,0,\n",
        "    1,1,1,1,1,1,0,\n",
        "    1,1,0,0,0,0,1,\n",
        "    1,1,0,0,0,0,1,\n",
        "    1,1,0,0,0,0,1,\n",
        "    0,1,1,1,1,1,0\n",
        "    ]\n",
        "\n",
        "    P=P.transpose()\n",
        "    \n",
        "    return (P,T)\n",
        "\n",
        "\n",
        "def gchar_ruido(P, Ruido):\n",
        "# Adds noise to the pattern P\n",
        "# Returns the noise pattern Pn\n",
        "\n",
        "    np.random.seed(int(time.perf_counter()))\n",
        "\n",
        "    Pn=np.zeros((63,16),dtype=int)\n",
        "\n",
        "    # Copy function! P is only a pointer!!\n",
        "    Pn=copiaV(P)\n",
        "    \n",
        "    BitsRuido=int(np.ceil(63*Ruido/100))\n",
        "    noise_ind=np.zeros((BitsRuido,1),dtype=int)\n",
        "\n",
        "    if BitsRuido == 0:\n",
        "        return P\n",
        "    \n",
        "    for l in range(16):\n",
        "        vals = np.random.rand(BitsRuido,1)*63\n",
        "        for k in range(BitsRuido):\n",
        "            noise_ind[k] = int(np.floor(vals[k]))\n",
        "           \n",
        "        for i in range(BitsRuido): \n",
        "            if Pn[l,noise_ind[i]] == 0: Pn[l,noise_ind[i]] = 1\n",
        "            else: Pn[l,noise_ind[i]] = 0\n",
        "        \n",
        "    return Pn\n",
        "\n",
        "def copia(x):\n",
        "    y=x\n",
        "    return y\n",
        "\n",
        "def copiaV(P):\n",
        "    f=np.vectorize(copia)\n",
        "    return f(P)\n",
        "\n",
        "def complement(x):\n",
        "    return -x+1\n",
        "\n",
        "def CompP(P):\n",
        "    f=np.vectorize(complement)\n",
        "    return f(P)\n",
        "\n",
        "def showChar(P):\n",
        "# Displays the 16 9x7 Characters\n",
        "\n",
        "    plt.figure(figsize=(18,14))\n",
        "    for i in range(16):\n",
        "        plt.subplot(4,4,i+1)        \n",
        "        Pc=CompP(P)\n",
        "        plt.imshow(Pc[i,:].reshape(9,7),cmap=cm.Greys_r)\n",
        "        plt.axis('off')    \n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def validacao(Pn,net):\n",
        "# calculate the output of the net for a given noise Patterns Pn\n",
        "# bincon - incorrect Chars; idx - the recognized pattern (should be range(16))\n",
        "\n",
        "    m=[]\n",
        "    idx=[]\n",
        "\n",
        "    # calculate predictions\n",
        "    predictions = net.predict(Pn)\n",
        "    for k in range(16):\n",
        "       p = predictions[k,:]\n",
        "       m.append(np.max(p))\n",
        "       idx.append(np.argmax(p))\n",
        "    \n",
        "    # calculate number or incorrect characters\n",
        "    bincor = 0; \n",
        "    for i in range(16): \n",
        "        if idx[i] != i: bincor +=1;\n",
        "            \n",
        "    return (bincor,idx)   \n",
        "\n",
        "N = 70  # Levels of noise\n",
        "Nnt = 40 # Number of training noise samples for each noise level\n",
        "Nnv = 4 # Number of validating noise samples\n",
        "NStep = 1  # Noise step\n",
        "\n",
        "P=[]  # Pattern\n",
        "T=[]  # Target\n",
        "Pn=[] # Noise Pattern\n",
        "fitT=np.zeros((N),dtype=int)  # Store the number of incorrect Chars while training\n",
        "fitV=np.zeros((N),dtype=int)  # Store the number of incorrect Chars while training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9_8nj_JF7pd"
      },
      "outputs": [],
      "source": [
        "# create models with 0, 10, 20 .... 90% noisy bit\n",
        "(P,T)=geraChar()\n",
        "Pn = gchar_ruido(P,10)\n",
        "showChar(Pn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK6iIfqWXD_w"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Creat a set of N ANNs\n",
        "Models=[]\n",
        "for i in range(N): # for each model    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, activation=\"sigmoid\", use_bias=True, bias_initializer=\"uniform\", kernel_initializer=\"uniform\", input_dim=63))\n",
        "    model.add(Dense(256, activation=\"sigmoid\", use_bias=True, bias_initializer=\"uniform\", kernel_initializer=\"uniform\"))\n",
        "    model.add(Dense(512, activation=\"sigmoid\", use_bias=True, bias_initializer=\"uniform\", kernel_initializer=\"uniform\"))\n",
        "    model.add(Dense(1024, activation=\"sigmoid\", use_bias=True, bias_initializer=\"uniform\", kernel_initializer=\"uniform\"))\n",
        "    model.add(Dense(16, activation=\"sigmoid\", use_bias=True, bias_initializer=\"uniform\", kernel_initializer=\"uniform\"))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    Models.append(model)\n",
        "\n",
        "print(\"Train networks\")   \n",
        "Models[0].fit(P, T, epochs=1000, batch_size=2048, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gZR2RjKbXD_w"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(1,N): # for each model\n",
        "# Learn Nstep epochs Noise Chars + epochs reforcing orig. Chars.\n",
        "\n",
        "    # Mantain Models[i-1] and proceed training with noise\n",
        "    Models[i].set_weights(Models[i-1].get_weights())\n",
        "\n",
        "    # test with different noise levels (at least once - range(i+1))\n",
        "    for k in range(Nnt):\n",
        "        Pn = gchar_ruido(P,NStep*i)\n",
        "        Models[i].fit(Pn, T, epochs=60, batch_size=256, verbose=0)\n",
        "        (incorr,idx) = validacao(Pn,Models[i])\n",
        "        fitT[i] += incorr\n",
        "\n",
        "    #Pn = gchar_ruido(P,0) # Reforce learning without noise \n",
        "    Models[i].fit(P, T, epochs=80, batch_size=256, verbose=0)\n",
        "    (incorr,idx) = validacao(P,Models[i])\n",
        "    fitT[i] += incorr\n",
        "\n",
        "    print(\"Rede i\",i,\"incorr\",str(np.round(fitT[i],2)))\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wNbsWlX4XD_y"
      },
      "outputs": [],
      "source": [
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png',show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glEkw1GcXD_y"
      },
      "outputs": [],
      "source": [
        "# Validate the trained ANN\n",
        "\n",
        "fitV=np.zeros((N),dtype=float)\n",
        "for i in range(N): # for each model\n",
        "    for k in range(Nnv):\n",
        "        Pn = gchar_ruido(P,NStep*i)\n",
        "        (incorr,idx) = validacao(Pn,Models[i])\n",
        "        fitV[i] += incorr\n",
        "FitV=np.round(100*fitV/(16*Nnv),2)\n",
        "print(\"Test ANN trained with 0%, 10%,...  noise. % incorrect Chars = \",FitV)\n",
        "\n",
        "fitO=np.zeros((N),dtype=float)\n",
        "for i in range(N): # for each model\n",
        "    for k in range(Nnv):\n",
        "        Pn = gchar_ruido(P,NStep*i)\n",
        "        (incorr,idx) = validacao(Pn,Models[0])\n",
        "        fitO[i] += incorr\n",
        "FitO=np.round(100*fitO/(16*Nnv),2)\n",
        "print(\"Test original (no noisy train) % incorrect Chars = \",FitO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoVaoTHpXD_z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,14))\n",
        " \n",
        "plt.plot(range(0,NStep*N,NStep),FitV, label=['Treinada'])\n",
        "plt.plot(range(0,NStep*N,NStep),FitV,'*')\n",
        "\n",
        "plt.plot(range(0,NStep*N,NStep),FitO, label=['Original'])\n",
        "plt.plot(range(0,NStep*N,NStep),FitO,'o')\n",
        "\n",
        "plt.title(['RNA treinada com  até ' + str(N*NStep) + '% de ruído'], fontsize=20)\n",
        "plt.ylabel([\"% Caracteres incorretos \" + str(Nnv*16) + ' por teste'], fontsize=20)\n",
        "plt.xlabel(['% Ruído teste, com ' + str(Nnv) +' amostras/nível de ruído'], fontsize=20)\n",
        "plt.legend(loc='upper left', fontsize=20)\n",
        " \n",
        "plt.savefig('figANN.pdf')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
